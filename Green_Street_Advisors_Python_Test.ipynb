{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Green Street Advisors Python Test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMT4rlVeh/dKl/B6+dMNDjW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnylp/JupyterNotebookCodes/blob/master/Green_Street_Advisors_Python_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Background:\n",
        "• We have collected data on single-family homes that we want to analyze.\n",
        "• [data_property.csv] contains a list of properties, but we are unsure of how \"clean\" the data is.\n",
        "• [data_rent.csv] contains rent data for these properties that was collected throughout 2019 (assume that this data has already been cleaned).\n",
        "• While analyzing the data, if you make any assumptions, explain what they are in comments.\n",
        "• When you are finished, submit the code that you have written and your output csv files, zipped into a compressed folder."
      ],
      "metadata": {
        "id": "CIa8SwssSD3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write code to parse / ingest [data_property.csv].\n",
        "2. Explore the data set, looking for potential errors, and clean the data set (this can be done manually by editing data_property.csv or programatically).\n",
        "3. Explain your methodology from #2 (this can be done in comments in your code).\n",
        "4. For each state: calculate the minimum square footage, maximum square footage, and the average age in years of all properties (age = current year - year_built).\n",
        "5. Output the results to a csv file, matching the [output_example_1.csv] format."
      ],
      "metadata": {
        "id": "lih8xXBldMKU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XZ96bAopR_gq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_property=pd.read_csv('/content/data_property.csv')"
      ],
      "metadata": {
        "id": "nRlVpBSzSOrH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport"
      ],
      "metadata": {
        "id": "6A2d3t5OTLkv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the null values"
      ],
      "metadata": {
        "id": "u7IqZRXASa4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_property.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVhfw9QlSUAU",
        "outputId": "b29cabda-a044-491b-b3ed-b2c25dbcc52d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "property_id     0\n",
              "address         0\n",
              "city            0\n",
              "state           0\n",
              "zip             0\n",
              "baths           0\n",
              "beds            0\n",
              "sf              0\n",
              "year_built     29\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking the data type of null values : Catgoerical or Intger"
      ],
      "metadata": {
        "id": "zjOAZzX5SebU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_property.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wknvuE8dSigs",
        "outputId": "733ee42d-db7d-432e-a6a7-1449154d3884"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "property_id      int64\n",
              "address         object\n",
              "city            object\n",
              "state           object\n",
              "zip             object\n",
              "baths          float64\n",
              "beds             int64\n",
              "sf              object\n",
              "year_built      object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_property.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g7Lq071SmkP",
        "outputId": "90b795a2-1af3-4c8d-e342-e5bd8071a436"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "766"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Percentage of missing value is less than 5%"
      ],
      "metadata": {
        "id": "zUiK24F6VXzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "29/766*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4bpfVzPVU3t",
        "outputId": "0617369d-04a4-4d33-9e83-33113d9eca32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7859007832898173"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still if we have to fill null data , simple approach is to look at mean median mode values. For categorical value we can use Mode more commonly."
      ],
      "metadata": {
        "id": "69wilASYVcGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_property['year_built']=data_property['year_built'].fillna(data_property['year_built'].mode()[0])"
      ],
      "metadata": {
        "id": "ndqnrF4ZYA5T"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_property['year_built'].value_counts().index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvK3u0YDagSp",
        "outputId": "d35a93ea-789b-4347-b3b0-f2fc15408de5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['2004', '2005', '2006', '2003', '2002', '1999', '2007', '2001', '2000',\n",
              "       '1997', '1998', '1996', '2008', '1995', '1994', '1989', '2009', '1990',\n",
              "       '1986', '2013', '1987', '1971', '1980', '1988', '1993', '1954', '1952',\n",
              "       '1925', '1985', '1974', '1992', '1951', '1977', '1955', '1970', '1950',\n",
              "       '1957', '1968', '1956', '1983', '2012', '1964', '1960', '1978', '1924',\n",
              "       '1917', '1984', '1973', '1962', '1981', '1959', '2010', '1947', '1926',\n",
              "       '1991', '1953', '1963', '2011', '1972', '2030', 'x', '1930', '1949',\n",
              "       '1975', '1938', '1907', '1935', '20009', '1958', '1976', '680', '1961',\n",
              "       '1942', '1929', '0', '1939', '1966', '203'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking at a set of years , data added seem to be wrong, so to correct need to identify wrong periods."
      ],
      "metadata": {
        "id": "NGhR_Mfva2vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wrongyears=['2030', 'x',  '20009', '680', '0', '203']"
      ],
      "metadata": {
        "id": "tOs8VagibA5l"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will correct these rows with imputing mode value"
      ],
      "metadata": {
        "id": "x08CZoSYbZbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_property.loc[data_property['year_built'].isin(wrongyears),'year_built']=data_property['year_built'].mode()[0]"
      ],
      "metadata": {
        "id": "KligDoTZbR8f"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_property['year_built'].value_counts().index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yujCYepbx_V",
        "outputId": "22e8bbc4-5eed-4dd6-ba9f-a5ffb5519f2a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['2004', '2005', '2006', '2003', '2002', '1999', '2007', '2001', '2000',\n",
              "       '1997', '1998', '1996', '2008', '1995', '1989', '1994', '2009', '1986',\n",
              "       '1990', '2013', '1987', '1988', '1980', '1971', '1952', '1993', '1954',\n",
              "       '1951', '1974', '1992', '1985', '1925', '1950', '1977', '2012', '1964',\n",
              "       '1957', '1983', '1970', '1956', '1960', '1968', '1955', '2010', '1924',\n",
              "       '1991', '1984', '1973', '1926', '1959', '1962', '1978', '1917', '1953',\n",
              "       '1981', '1947', '1975', '1972', '1958', '1961', '1942', '1929', '1938',\n",
              "       '1939', '1930', '2011', '1907', '1966', '1949', '1963', '1935', '1976'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_property['age']=2022 - data_property['year_built'].astype(int)"
      ],
      "metadata": {
        "id": "0zJOH_d9b6S7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Years clean up is completed"
      ],
      "metadata": {
        "id": "UJSsjPnfb1H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sf_min=data_property[['state','sf']].groupby('state').min().reset_index()\n",
        "sf_max=data_property[['state','sf']].groupby('state').max().reset_index()\n",
        "age_avg=data_property[['state','age']].groupby('state').mean().reset_index()"
      ],
      "metadata": {
        "id": "rzHHK4heVgzc"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= sf_min.merge(sf_max,on='state').merge(age_avg,on='state')"
      ],
      "metadata": {
        "id": "XPOVhxNYcJhu"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=['state', 'sf_min', 'sf_max', 'age_avg']"
      ],
      "metadata": {
        "id": "4ksg3MXDc33P"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('output_example_1.csv')"
      ],
      "metadata": {
        "id": "eeUmg54Vc_MN"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem statement 2"
      ],
      "metadata": {
        "id": "cndx27yidG_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. Parse / ingest [data_rent.csv].\n",
        "7. Calculate how many rent data points were collected for each property and output to a csv file, matching the [output_example_2.csv] format.\n",
        "8. Calculate how many properties had a rent increase during 2019 and output to the console.\n",
        "9. Join the 2 data sets to calculate how many CA properties have a rent observation on 2019-05-27 and output to console.\n",
        "10. Given a larger data set and more time, explain how your cleaning methodology from step 2 would change (this can be done in comments in your code)."
      ],
      "metadata": {
        "id": "WEd44W79dQ3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_rent=pd.read_csv('/content/data_rent.csv')"
      ],
      "metadata": {
        "id": "2MtK1vfHdIne"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate how many rent data points were collected for each property"
      ],
      "metadata": {
        "id": "UKx5ToZMd-uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rentdatapoints=data_rent['property_id'].value_counts().reset_index().sort_values('index')\n",
        "rentdatapoints.columns=['property_id','number_observations_rent']"
      ],
      "metadata": {
        "id": "Ob3C80ybdXBE"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rentdatapoints.to_csv('output_example_2.csv')"
      ],
      "metadata": {
        "id": "RHvbP1sUeYrS"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join the 2 data sets to calculate how many CA properties have a rent observation on 2019-05-27 and output to console."
      ],
      "metadata": {
        "id": "vD9phw39e39J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_rentupdated=data_rent.merge(data_property[['property_id','state']],on='property_id',how='left')"
      ],
      "metadata": {
        "id": "8Lz-weBge7V1"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rentobserved= data_rentupdated[(data_rentupdated['state']=='CA') & (data_rentupdated['date'].astype(str)=='5/27/2019')]"
      ],
      "metadata": {
        "id": "oHCK7v3Bfisb"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a larger data set and more time, explain how your cleaning methodology from step 2 would change (this can be done in comments in your code)"
      ],
      "metadata": {
        "id": "gqjPbiqGgByK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Some of the very simple techniques we can use is we can use ML approach to impute the missing values.\n",
        "2. But even before jumping on to ML we will keep it simple using mean , median and mode values. We will test our model accuracy with that.\n",
        "3. We can try KNN algorithm to fill null values or we can try decision trees for this particular use case.\n",
        "5. There is a SMOTE technique as well to fill null values.\n",
        "6. With each trial and error we will keep on testing model accuracy to understand relevant approach to pic and choose"
      ],
      "metadata": {
        "id": "8ufafRx2gFRK"
      }
    }
  ]
}