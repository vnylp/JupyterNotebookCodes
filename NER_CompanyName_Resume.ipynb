{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_CompanyName_Resume.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkz2gTqhW2bZpch73NBtTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnylp/JupyterNotebookCodes/blob/master/NER_CompanyName_Resume.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "-i8UDCaQKEzj",
        "outputId": "af5e2eef-b576-4fd1-da9f-c366dc5c86f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(\"Harini Komaravelli\\nTest Analyst at Oracle, Hyderabad\\n\\nHyderabad, Telangana - Email me on Indeed: indeed.com/r/Harini-\\nKomaravelli/2659eee82e435d1b\\n\\n➢ 6 Yrs. of IT Experience in Manual and Automation testing.\\n\\nWORK EXPERIENCE\\n\\nQA Analyst\\n\\nOracle\\n\\nTest Analyst at Oracle, Hyderabad\\n\\nInfosys Ltd -  Hyderabad, Telangana -\\n\\nNovember 2011 to February 2016\\n\\nHyderabad from Nov 2011 to Feb17 2016\\n➢ Worked in Tata Consultancy Services, Hyderabad from Feb 24 to Apr 11 2017\\n➢ Currently working as a Test Analyst at Oracle, Hyderabad\\n\\nQA Analyst with 6 years of IT experience\\n\\nOracle\\n\\nEDUCATION\\n\\nMCA\\n\\nOsmania University\\n\\nB.Sc. in Computer Science\\n\\nOsmania University\\n\\nSKILLS\\n\\nFunctional Testing, Blue Prism, Qtp\\n\\nADDITIONAL INFORMATION\\n\\nArea of Expertise:\\n\\n➢ Familiar with Agile Methodologies.\\n➢ Having knowledge in Energy (Petroleum) & Health Care domains.\\n➢ Involved in preparation of Test Scenarios.\\n➢ Preparing Test Data for the test cases.\\n\\nhttps://www.indeed.com/r/Harini-Komaravelli/2659eee82e435d1b?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Harini-Komaravelli/2659eee82e435d1b?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n➢ Experienced in development and execution of Test cases effectively.\\n➢ Experienced in Functional testing, GUI testing, Smoke testing, Regression testing and\\nIntegration Testing\\n➢ Experienced in doing Accessibility testing of an application\\n➢ Ability to understand user Requirements, Functional and Design specifications.\\n➢ Good knowledge of SDLC and STLC processes.\\n➢ Deciding the Severity and Priority of bugs.\\n➢ Experience in using Microsoft Test Manager & Oracle Test Manager as Test Management Tools.\\n➢ Having good experience in testing windows based & web based applications.\\n➢ Involved in Client Interactions for reviews, issues and for any clarifications.\\n➢ Web Services Testing\\n➢ Writing Test Scripts in QTP, Testcomplete.\\n➢ Creating Object Repositories and Function Libraries in QTP.\\n➢ Enhanced QTP scripts using VB Script.\\n➢ Strong experience in working with Blue Prism tool\\n➢ Worked on different Environments like Windows Application & Web Application\\n\\nTechnical Skills:\\n\\n❑ Test Automation Tools: Blue Prism, QTP 10.0, Testcomplete\\n❑ Test Management Tool: Microsoft Test Manager, Oracle Test Manager & JIRA\\n❑ Databases: Oracle 10g, SQL Server.\\n\\n❑ Operating Systems: Windows 7\\n\\nProject 1:\\nTitle: Cadence\\nClient: Baker Hughes\\n\\nTechnologies: Microsoft Visual Studio and Microsoft Team Foundation Server\\n\\nClient Background:\\nAn oilfield services company delivering focused efforts on shale gas and other oilfield services.\\nIt provides services, tools and software for drilling and formation evaluation, well completion,\\nproduction management, seismic data collection and interpretation.\\n\\nProject Description:\\nAUT (Application under test) is the next generation revolutionary, robust, easy to use scalable\\nwell site data acquisition processing and interpretation system for Client's Drilling Services to\\ndeliver services that meets cross divisional business requirements consistently.\\n\\nProject 2:\\n\\nDescription:\\nParagon supports your entire care team with one tool that your clinicians need to help deliver\\nthe best patient care. Designed by physicians, nurses, pharmacists and mid level providers that\\nhave a first-hand understanding of clinical workflow needs, Paragon clinical applications allow\\nyour caregivers to focus on what matters most; spending time caring for patients. Since Paragon\\nis fully-integrated across all applications and built around a single patient database, information\\n\\n\\n\\nentered anywhere in the system is immediately available to the entire care team. Immediate\\naccess not only helps clinicians make better treatment decisions - it also helps promote patient\\nsafety. Paragon offers a broad suite of multidisciplinary clinical software solutions together with\\nanytime, anywhere access to the complete patient record.\\n\\nResponsibilities:\\n\\n• Performed Smoke testing and Regression testing.\\n• Involved in Generating and Executing Test Script using Quick Test Pro & Blue Prism\\n• Usability and User Interface Testing.\\n• Involved in Defect tracking and reporting the bugs using TFS\\n• Participated in frequent walk-through meetings with Internal Quality Assurance groups and with\\ndevelopment groups.\\n• Participated in client calls and clarifying the doubts by having AT&T sessions\\n• Involved in functional, regression and smoke testing to validate the application data changes\\ndone in windows application\\n• Certifying the build status by running the scripts as part of smoke testing\\n\\nProject 3:\\n\\nDescription:\\nFood & Beverages R&A: Easily manage business across multiple locations while reducing IT\\ncost and complexity. Cloud-based point-of-sale (POS) solutions enable centralized enterprise\\nmanagement with lower upfront costs and a smaller footprint.\\n\\nResponsibilities:\\n\\n• Performed Functional testing and Regression testing.\\n• Involved in Generating and Executing Test Scripts using Blue Prism tool and Open script\\n• Involved in preparing bots using Blue Prism tool.\\n• Accessibility testing of the web application\\n• Involved in Defect tracking and reporting the bugs using JIRA\\n• WebServices testing by calling API's to export the data\", {'entities': [(2275, 2281, 'Companies worked at'), (2235, 2241, 'Companies worked at'), (1603, 1609, 'Companies worked at'), (667, 703, 'Skills'), (638, 658, 'College Name'), (612, 637, 'Degree'), (591, 611, 'College Name'), (587, 590, 'Degree'), (568, 574, 'Companies worked at'), (526, 536, 'Designation'), (515, 524, 'Location'), (507, 513, 'Companies worked at'), (491, 503, 'Designation'), (429, 438, 'Location'), (352, 361, 'Location'), (296, 305, 'Location'), (270, 279, 'Location'), (262, 268, 'Companies worked at'), (246, 258, 'Designation'), (238, 244, 'Companies worked at'), (226, 236, 'Designation'), (177, 207, 'Designation'), (150, 155, 'Years of Experience'), (54, 63, 'Location'), (43, 52, 'Location'), (35, 41, 'Companies worked at'), (19, 31, 'Designation'), (0, 18, 'Name')]}), ('Hartej Kathuria\\nData Analyst Intern - Oracle Retail\\n\\nBengaluru, Karnataka - Email me on Indeed: indeed.com/r/Hartej-Kathuria/04181c5962a4af19\\n\\nWilling to relocate to: Delhi - Bangalore, Karnataka - Gurgaon, Haryana\\n\\nWORK EXPERIENCE\\n\\nData Analyst Intern\\n\\nOracle Retail -  Bengaluru, Karnataka -\\n\\nJune 2017 to Present\\n\\nJob Responsibilities:\\no As an intern part of the Global Retail Insights team at Oracle Retail,\\nwork involved creating a data oriented buisness case based using high\\nlevel trends for various retailers using Excel and SQL.\\no Forecasting Sales with use of various statistical Modelling Methods\\nusing SQL and R\\no Market Basket Analysis using transactional data of retailers using SQL and R\\n\\nEDUCATION\\n\\nStatistics and Probability\\n\\nManipal University\\n\\nMay 2018\\n\\nB. Tech in Electrical and Electronics in Embedded Systems\\n\\nMIT, Manipal University\\n\\nMay 2016\\n\\nSKILLS\\n\\nPython (2 years), SQL. (1 year), NOSQL (1 year), R (2 years), Machine Learning (2 years)\\n\\nPUBLICATIONS\\n\\nPost-operative life expectancy in lung cancer patients\\n\\nThe objective of the project was to build an efficient predictive model based\\non a predefined dataset to predict whether the patient survives or dies within one year of the\\noperation. The dataset given has 17 variables: 12 nominal, 2 ordinal and 3 numerical. The target\\nvariable has value true if the patient dies within one year of the operation else false if he survives.\\nTool used: R\\n\\nhttps://www.indeed.com/r/Hartej-Kathuria/04181c5962a4af19?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nPredict the Happiness (Sentimental Analysis)\\n\\nThe objective of this project was to build a binary classifcation model for the data provided by\\nTripAdvisor consisiting of a sample of hotel reviews provided by customers.The model built can\\nbe used by them to understand the hotels\\nlisted by them.Tool Used: R\\n\\nPredict Network attacks\\n\\nThe objective of this project was to build a multi-class classification model to predict the type of\\nattack for an internet network company in Japan which has\\nbeen facing huge losses due to malicious server attacks.The train dataset has\\n18 numerical features and 23 categorical features.The target variable has\\nthree classes.Tool Used: Python\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLSET\\n\\n• Languages & Technologies: Python, R, SQL, NoSQL, Predictive Modelling,\\nMarket Basket Analysis, Sentimental Analysis, Clustering, Bash\\nScripting (Preliminary), Socket Programming, Java (Preliminary)\\n\\n• Tools: R Studio, Jupyter, GIT, Sublime, MATLAB, Linux, KVM, Virtual Box,\\nOpen VZ, Oracle SQL Developer, MySQL, MongoDB, Excel', {'entities': [(2246, 2573, 'Skills'), (1435, 1480, 'Email Address'), (875, 964, 'Skills'), (861, 865, 'Graduation Year'), (837, 856, 'College Name'), (773, 830, 'Degree'), (767, 771, 'Graduation Year'), (743, 762, 'College Name'), (714, 741, 'Degree'), (271, 280, 'Location'), (233, 252, 'Designation'), (96, 141, 'Email Address'), (53, 62, 'Location'), (38, 52, 'Companies worked at'), (16, 35, 'Designation'), (0, 15, 'Name')]}), (\"Ijas Nizamuddin\\nAssociate Consultant - State Street\\n\\nIrinchayam B.O, Kerala - Email me on Indeed: indeed.com/r/Ijas-\\nNizamuddin/6748d77f76f94eed\\n\\nWith close to 3 years of experience in IT industry, I have had excellent exposure to design,\\ndevelopment and implementation of Client Server Applications in various domains such as\\nBanking and Finance concepts. I have been involved in various software Development projects\\nin Open System environment.\\n\\nWORK EXPERIENCE\\n\\nAssociate Consultant\\n\\nOracle Corporation -\\n\\nJune 2011 to Present\\n\\nState Street Global Advisors (SSgA) is the asset management business of State Street\\nCorporation, one of the world's leading providers of financial services to institutional investors1,\\nwith a heritage dating back over two centuries. Backed by the strength and stability of the State\\nStreet organization, SSgA makes continual investments in asset management and client service\\nplatform, resulting in a client-focused, solutions-driven orientation .BrokerViews is the application\\nwhich list all the details about the counterparties who invest their securities in State Street.The\\ndetails also include ratings given by Bloomberg.\\n\\nResponsibilities: Development, Testing and support.\\nSoftware Used: Java, GWT\\n\\nAssociate Consultant\\n\\nOracle Corporation -  Bangalore, Karnataka -\\n\\nMay 2010 to June 2011\\n\\nThis project is actually a redesign of an existing client website. The client website was designed\\non Java Server Pages (JSP) and our aim was to change it into a more dynamic web page using\\nAdobe Flex. At first we changed the home page screen of the client website. After the successful\\ncompletion of that we incorporated flex in to the account section also. This data which is obtained\\nfrom DataBase is taken by the flex using a remote procedure call and the data is shown to the\\nuser. With the use of Advanced Data Grids, Charts(including Bar and Pie Charts) the site increased\\nthe readability and understandability of the users who were previously using the pages on java\\nserver pages. This site developed by us won the IMC (Interactive Media Council)'s outstanding\\nachievement award in Financial information. The judge evaluate website based on 5 criteria:\\nDesign, Content, Feature Functionality, Usability and Standard Compliance. Our website scored\\n475 out of a maximum of 500 points.\\n.\\nResponsibilities: Development, Testing and support.\\nSoftware Used: Java, Adobe Flex\\n\\nhttps://www.indeed.com/r/Ijas-Nizamuddin/6748d77f76f94eed?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Ijas-Nizamuddin/6748d77f76f94eed?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nFramework: Springs, MVC\\n\\nAssociate Consultant\\n\\nOracle Corporation -  Bangalore, Karnataka -\\n\\nFebruary 2010 to April 2010\\n\\nDescription: Development of Basel II Application, Basel II is the second of the Basel Accords,\\nwhich are recommendations on banking laws and regulations issued by the Basel Committee on\\nBanking Supervision. The purpose of Basel II, which was initially published in June 2004, is to\\ncreate an international standard that banking regulators can use when creating regulations about\\nhow much capital banks need to put aside to guard against the types of financial and operational\\nrisks banks face. In practice, Basel II attempts to accomplish this by setting up rigorous risk\\nand capital management requirements designed to ensure that a bank holds capital reserves\\nappropriate to the risk the bank exposes itself to through its lending and investment practices.\\n\\nThe New Accord includes several methodologies for determining a bank's risk-based capital\\nrequirements for credit, market and operational risk. For Risk Based Capital (RBC), Credit Usage\\n(CU) and Stress Test (ST), the methodologies that will be used for repo style transactions are\\nSimple VaR if the collateral is eligible. If the collateral is ineligible then the Wholesale loan\\napproach will be utilized or the collateral will be reduced to zero in the Simple VaR.\\n.\\nRoles and Responsibilities: Development, Testing and support.\\nSoftware Used: Oracle 9i\\n\\nOTHER PROJECTS AND REAL TIME TRAINING:\\n\\nRTRM(Railway Ticketing System Through Mobile)\\nA mobile based real time application with many exciting features like checking pnr status, train\\navailability, trains between stations etc. This application was done in j2me and it uses weblogic\\nas server and MSSQL as the database.\\n\\nUndergone a mandatory Training on Finance By Oracle Corporation\\n\\nEDUCATION\\n\\nBirla Institute Of Technology -  Pilani, Rajasthan\\n\\n2011\\n\\nBachelor of Technology in Computer Science\\n\\nUniversity College Of Engineering, University Of Kerala\\n\\n2005 to 2009\\n\\nADDITIONAL INFORMATION\\n\\nSKILL SET:\\n\\n\\n\\nLanguages: Core Java\\nFront end/GUI Tools programming: Adobe Flex, GWT\\nDatabase: Oracle 10g\\nIDE: Eclipse, FlexBuilder\\nFrameWorks: Spring(Basics), MVC frame work\\nOperating System: Windows, Linux, Unix\", {'entities': [(4652, 4850, 'Skills'), (4607, 4612, 'Graduation Year'), (4543, 4576, 'College Name'), (4499, 4541, 'Degree'), (4493, 4498, 'Graduation Year'), (4441, 4471, 'College Name'), (4410, 4428, 'Companies worked at'), (2654, 2672, 'Companies worked at'), (2632, 2652, 'Designation'), (1323, 1328, 'Graduation Year'), (1260, 1278, 'Companies worked at'), (1238, 1258, 'Designation'), (603, 616, 'Companies worked at'), (487, 505, 'Companies worked at'), (465, 485, 'Designation'), (97, 144, 'Email Address'), (53, 67, 'Location'), (39, 52, 'Companies worked at'), (16, 36, 'Designation'), (0, 15, 'Name')]}), ('Imgeeyaul Ansari\\njava developer\\n\\nPune, Maharashtra - Email me on Indeed: indeed.com/r/Imgeeyaul-Ansari/a7be1cc43a434ac4\\n\\nWilling to relocate to: Pune, Maharashtra\\n\\nWORK EXPERIENCE\\n\\nApplication Developer\\n\\nOracle Financial Software Services -  Pune, Maharashtra -\\n\\nAugust 2016 to Present\\n\\n• Wrote Services in java using data annotation which in turn were used for creating other files\\nusing code generation tool.\\n\\n• Jar of services with related utility files such as DTOs are deployed on the Host side.\\n\\n• Host side is hosted on Tomcat Server where proxy files are present.\\n\\n• Created jsff page for UI, and wrote action, helper, assembler, backing bean for UI side business\\nLogic made entries in collectionAppModule, PageDef.\\n\\n• Used ADF & MVC architecture for building application.\\n\\nUsed JUnit for Testing services,Algorithms.\\nAlso made test Suites For running multiple test case at one go.\\n\\nUsed Eclipse Debugger for Fixing Service Related Jiras.\\nMade Use of Hot Deployment for Fixing Ui related Bugs on UI side which was run on Weblogic\\nServer. \\nUsed JAWS Reader for solving accessibility Related jiras and IA plugin.\\n\\nUsed Java to write Batches for fetching of Bulk Data at Regular Interval.\\nIt created Thread for Multitasking to reduce the time for processing.\\n\\nEDUCATION\\n\\nBachelor of Enginerring in Information Technology\\n\\nArmy institute of technology -  Pune, Maharashtra\\n\\n2012 to 2016\\n\\nCBSE in Physics, Chemistry, Mathematics\\n\\nRashtriya Military School Bangalore -  Bengaluru, Karnataka\\n\\nhttps://www.indeed.com/r/Imgeeyaul-Ansari/a7be1cc43a434ac4?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n2010 to 2011\\n\\nCBSE in Mathematics and English\\n\\nRashtriya Military School Bangalore -  Bengaluru, Karnataka\\n\\n2008 to 2009\\n\\nSKILLS\\n\\nJAVA (1 year), CSS (1 year), HTML (1 year), MYSQL (1 year), JAVASCRIPT (Less than 1 year),\\nAngularjs (1 year), Oracle Pl/Sql\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS\\nProgramming Languages :C/C++, angular, java, java servlet, HTML, java script, MySQL, css, jsff.\\n\\nOperating Systems Linux, Windows, Android\\n\\nORM Eclipse Link, Hibernate\\n\\nFramework & tools :ADF, Eclipse, Android Studio, Git, Selenium, Code blocks, Net beans, R studio,\\nTortoise SVN.', {'entities': [(1894, 2173, 'Skills'), (1726, 1851, 'Skills'), (1711, 1716, 'Graduation Year'), (1643, 1678, 'College Name'), (1610, 1642, 'Degree'), (1433, 1468, 'College Name'), (1385, 1390, 'Graduation Year'), (1359, 1363, 'Location'), (1327, 1356, 'College Name'), (1276, 1325, 'Degree'), (269, 274, 'Graduation Year'), (242, 246, 'Location'), (204, 238, 'Companies worked at'), (181, 202, 'Designation'), (145, 149, 'Location'), (33, 37, 'Location'), (17, 31, 'Designation'), (0, 16, 'Name')]}), ('Jay Madhavi\\nNavi Mumbai, Maharashtra - Email me on Indeed: indeed.com/r/Jay-\\nMadhavi/1e7d0305af766bf6\\n\\nI look forward to being associated with a growth - oriented, learning firm and\\ncontribute my skills for its success. This will allow me to grow both professionally\\nas well as an individually.\\n\\nWORK EXPERIENCE\\n\\nNIIT -\\n\\n2016 to 2016\\n\\nB+ Average\\nAdvanced\\n\\nSQL Oracle -\\n\\n2016 to 2016\\n\\nB+ Average\\n\\nMSCIT -\\n\\n2011 to 2011\\n\\nA Completed\\nTechnical Institution\\n\\nProjects undertaken (BE):\\n\\nS.N. Project Title Name of company/college Nature of the Remarks\\nproject\\n\\n1 Android Based Saraswati College Of Android Completed\\nEmployee Tracker Engineering Application\\nSystem\\n\\n2 An innovative Saraswati College Of Compilation Completed\\napproach for Engineering\\ncode optimization\\n\\n3 Simple Website Saraswati College Of Website related to Completed\\nRelated to Engineering information of\\nClassical Italian cars\\nCars\\n\\nAbout Myself:\\n• I am Capable and Hardworking, and can adapt to New Surroundings.\\n\\nhttps://www.indeed.com/r/Jay-Madhavi/1e7d0305af766bf6?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Jay-Madhavi/1e7d0305af766bf6?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n• I Can Face Challenges with confidence and would give my best shot under Stressful situations.\\n\\n.. 03 : 03:\\n\\nEDUCATION\\n\\nBE (Computer Science) in Computer Science\\n\\nSaraswati College Of Engineering, Kharghar -  Mumbai, Maharashtra\\n\\n2014 to 2017\\n\\nHSC in Computer science\\n\\nAcharya College Chembur -  Mumbai, Maharashtra\\n\\n2011 to 2013\\n\\nSSC\\n\\nState Board\\n\\n2011\\n\\nADDITIONAL INFORMATION\\n\\n• Ability to accept responsibilities and give best performance to complete the given work\\nefficiently.\\n• To take up challenging jobs & work as a team.\\n• To positively accept my Mistake.', {'entities': [(1520, 1524, 'Graduation Year'), (1507, 1518, 'Degree'), (1496, 1500, 'Graduation Year'), (1488, 1492, 'Graduation Year'), (1440, 1463, 'College Name'), (1415, 1439, 'Degree'), (1409, 1413, 'Graduation Year'), (1334, 1366, 'College Name'), (1291, 1333, 'Degree'), (917, 940, 'Skills'), (413, 417, 'Graduation Year'), (405, 409, 'Graduation Year'), (356, 368, 'Skills'), (313, 318, 'Companies worked at'), (51, 101, 'Email Address'), (12, 23, 'Location'), (0, 11, 'Name')]}), (\"Jitendra Babu\\nFI/CO Consultant in Tech Mahindra - SAP FICO\\n\\nChennai, Tamil Nadu - Email me on Indeed: indeed.com/r/Jitendra-Babu/bc3ea69a183395ed\\n\\n• Having 3.2-years of SAP experience as sap FICO Consultant\\n• Involved in Implementation and support projects\\n• Basic knowledge in simple finance.\\n• Proficient in SAP's ASAP Methodology and well versed with business process, its mapping &\\nconfiguration in SAP\\n• Good inter-personal skills, strong analytical ability and problem-solving capabilities\\n• Ability to make timely and sound decisions based on logical assumptions, factual information.\\n• Ability to work as a team member supporting co-workers and the commitment to the overall\\nsuccess of a group.\\n• Work effectively with internal customers, co-workers and management.\\n• Knowledge on integration of FI with other modules like MM and SD\\n• Experience in GL, AP, and AR\\n• Good communication skills with an aptitude to interact with the clients for Production support\\n• Good Understanding of business process in Industry.\\n• Expertise on data uploading tolls-LSMW\\n• Good exposure on writing validation and substitution rules for business requirements and\\nwriting queries.\\n• Interacting with the end user and finalizing the user requirement\\n• Coordinating with the other teams for SAP integration aspects\\n• Well exposure on designing the organization structure and setting it up in SAP in association\\nwith other members from different streams of the implementation team.\\n• Detail oriented, quick learner, good listener with strong problem solving skills.\\n\\nSAP FICO SKILL SET:\\n\\nFinance\\n• Financial Accounting- General Ledger Accounting FI-G/L (New GL),\\n• Accounts Payable-FI-A/P,\\n• Accounts Receivable FI-A/R\\n\\nWORK EXPERIENCE\\n\\nFI/CO Consultant in Tech Mahindra\\n\\nSAP FICO -\\n\\n2015 to Present\\n\\nSAP FICO Consultant\\n\\nSAP FICO -\\n\\nApril 2017 to May 2018\\n\\nProject & Role Description:\\n\\nhttps://www.indeed.com/r/Jitendra-Babu/bc3ea69a183395ed?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nFossil Group, Inc., together with its subsidiaries, designs, develops, markets, and distributes\\nconsumer fashion accessories. The company's principal products include a line of men's and\\nwomen's fashion watches and jewelry, handbags, small leather goods, belts, and sunglasses. It\\noffers its products under its proprietary brands, such as FOSSIL, MICHELE, MISFIT, RELIC, SKAGEN,\\nand ZODIAC, as well as under the licensed brands, including ARMANI EXCHANGE, CHAPS, DIESEL,\\nDKNY, EMPORIO ARMANI, KARL LAGERFELD, KATE SPADE NEW YORK, MARC JACOBS, MICHAEL\\nKORS, and TORY BURCH. The company sells its products through company-owned retail stores,\\ndepartment stores, specialty retail stores, specialty watch.\\nRoles and Responsibilities:\\n• Resolving Day to Day issues as well as providing Solution for better Business Processes.\\n• Adhere to the SLA timelines\\n• Coordinating with technical consultants for modifications in outputs and program changes\\n• Handling various support issues be it process, configuration or functionality issue.\\n• Migrated Transaction and Master Data using migration tool LSMW\\n• Effective defect tracking, reporting and documenting the deliverables\\n• Handling knowledge transfer sessions to the new comers in the team\\n• Participation in regular team members meetings who are part of this support project and SAP\\nFICO team in scope.\\n• Conducting the Core-Team Training.\\n• Configuring new payment terms\\n• Defined new payment terms as per the business requirements for Vendors.\\n• Actively involved in Table maintenance\\n• Preparing the Root cause analysis, Back log report and SLA adherence report inputs to team\\nleader from time to time.\\n• Supporting the end users while running the Automatic Payment Program\\n• Creating new Validations and Substitutions for posting transactions requirements.\\n• Working closely with all members of the team to clear the backlog tickets.\\n• Good Exposure towards Ticketing tool\\n• Resolved Automatic payment program issues / bugs in implementing SAP OSS Notes.\\n\\nDOMAIN EXPERIENCE:\\n• Worked under Auditor for 6 months as a assistant in Tally ERP 9.0 package.\\n\\nSAP FICO -\\n\\nMarch 2015 to March 2017\\n\\nProject & Role Description:\\nFord India Private Limited manufactures, distributes, and exports cars, SUVs, sedans, and\\nlow displacement engines. It offers total maintenance, extended warranty, scheduled service,\\npreferred insurance, and mobile service plans. The company sells its products through\\ndealers to individuals, fleet organizations/rental companies, corporate, embassy/consulates and\\nprofessionals, and government organizations; and sales and service outlets.\\nRoles and Responsibilities:\\n• Exposure towards value ASAP methodology\\n• Co-ordination with core team and Preparation of Businesses Blue Print for the complete business\\nprocess.\\n• Documented in AS IS & TO BE document\\n• Involved in WRICEF elements\\n• Involved in positive, negative & random testing\\n\\n\\n\\n• Involved in data upload\\n• Involved in SAP customizing, configuring and processing the Business Transactions in Finance.\\n• Configured and Customized the G/L account master records, G/L Account groups\\n• Define field status variant. Define number range\\n• Expertise on data uploading tolls-LSMW\\n• Create and Maintain the Master Accounts for GL,\\n• Creating vendors and customer master data\\n• Configuration of automatic payment program\\n• Exposure on writing validation and substitution rules for business requirements\\n\\nProject:\\n\\nEDUCATION\\n\\nB.com\\n\\nDegree College -  Machilipatnam, Andhra Pradesh\\n\\n2014\\n\\nAG&SGS Intermediate College\\n\\n2011\", {'entities': [(5510, 5514, 'Graduation Year'), (5481, 5508, 'College Name'), (5475, 5479, 'Graduation Year'), (5426, 5440, 'College Name'), (5419, 5425, 'Degree'), (4077, 4085, 'Companies worked at'), (1810, 1818, 'Companies worked at'), (1789, 1797, 'Companies worked at'), (1760, 1768, 'Companies worked at'), (1725, 1758, 'Designation'), (1555, 1563, 'Companies worked at'), (155, 166, 'Years of Experience'), (101, 145, 'Email Address'), (60, 67, 'Location'), (50, 58, 'Companies worked at'), (14, 47, 'Designation'), (0, 13, 'Name')]}), ('Jyotirbindu Patnaik\\nAssociate consultant@SAP labs , Bangalore Karnataka\\n\\nBengaluru, Karnataka - Email me on Indeed: indeed.com/r/Jyotirbindu-\\nPatnaik/77e3ceda47fbb7e4\\n\\n-\\nExperienced incident and change coordinator and strongly skilled and dedicated ITIL Expert with\\na superior work ethic and management satisfaction record. Widely and deeply knowledgeable\\nin all aspects of ITIL management and coordination. Adept multitasker able to deal a very high\\npriority complex situations with accuracy and professionalism.\\n\\nWilling to relocate to: Bangalore, Karnataka\\n\\nWORK EXPERIENCE\\n\\nAssociate consultant\\n\\nSap labs\\n\\nIncident and change management coordinator,\\ndealing with the escalation process of company products.\\nNotifying the customer as well as stake holders regarding the on going issue as well as helping\\nproblem management team to provide RCA.\\n\\nAssociate consultant\\n\\nSap labs\\n\\n-\\nJoining date from: January 25, 2017\\nDesignation: Associate Consultant\\nCompany: SAP on the payroll of Bristlecone India LTD.\\n\\nRoles and responsibilities: -\\nIncident Coordinator:\\n1. Following the escalation process and handling the high priority incidents by initiating the\\ntroubleshooting call and driving the entire call till the issue gets resolve.\\n2. Capturing the entire chronological order to provide the RCA for the unplanned downtimes.\\n3. As an incident coordinator, I was informing the internal stakeholders regarding the unplanned\\ndowntimes/high priority issue by sending the notifications periodically.\\n4. Post handling the issue we were updating the MTTR and monthly outage tracker to have a\\nclear records of unplanned downtimes.\\n5. Monitoring the tools like Catchpoint, Pingdom, CSS for quick find of availability alerts and trying\\nto troubleshoot by initial analysis ASAP.\\n6. Preparing the documents for all the new process and update it as per its new changes.\\n7. Providing the reports (KPI/Availability/IRT-MPT) on weekly and monthly basis to the\\nmanagement to minimize the number incidents.\\n8. I was analyzing regarding the number of incidents and alerts received, and providing the entire\\ncaptured details to management for further process to reduce the incidents and alerts.\\n\\nhttps://www.indeed.com/r/Jyotirbindu-Patnaik/77e3ceda47fbb7e4?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Jyotirbindu-Patnaik/77e3ceda47fbb7e4?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nChange Coordinator:\\n9. As a change, Coordinator was handling the Entire change management process and validating\\nthe Change requests to get the CAB approvals.\\n10. Providing the KPI report for the change process.\\n11. Driving the CAB meeting and KPI meeting.\\n\\nProjects: -\\nI was working for \"Cloud for customer\" and \"Business by design\" project in SAP.\\n\\nAchievements: -\\n1. I have received management appreciation note for handling the change management process\\nin a proficient way.\\n2. Team Lead appreciated for maintaining the documents and PPT\\'s as updated.\\n\\nEDUCATION\\n\\nB. Tech in Electronics and Communication\\n\\nBiju Patnaik University -  Rayagada, Orissa\\n\\n2016\\n\\nSKILLS\\n\\nITIL foundation', {'entities': [(3052, 3067, 'Skills'), (2993, 3016, 'College Name'), (2951, 2992, 'Degree'), (870, 878, 'Companies worked at'), (847, 868, 'Designation'), (600, 608, 'Companies worked at'), (577, 598, 'Designation'), (116, 167, 'Email Address'), (73, 82, 'Location'), (19, 40, 'Designation'), (0, 19, 'Name')]}), ('Karthik GV\\nArchitect - Microsoft India\\n\\nHyderabad, Telangana - Email me on Indeed: indeed.com/r/Karthik-GV/1961c4eff806e6f4\\n\\nWilling to relocate to: hyderbad, Telangana\\n\\nWORK EXPERIENCE\\n\\nArchitect\\n\\nMicrosoft India -  Hyderabad, Telangana -\\n\\nFebruary 2005 to Present\\n\\n• DevOps - One of the key members of the DevOps team in the Enterprise Services Global DevOps\\nprogram.\\n• Readiness - Provide DevOps readiness to the end customer.\\n\\nSr. Program Manager\\n\\nMicrosoft India -\\n\\nMarch 2016 to January 2018\\n\\nKey Projects - Aurora BI (SAP), ES Analytics, BI as a Service, Service Center BI, Premier services\\n(PSR)\\n\\nI am accountable for implementing a unified analytical platform for the entire Enterprise Services\\nbusiness (~$6 billion) in Microsoft. This allows the services business to strategize and take key\\noperational decisions during the monthly and quarterly business reviews with the Leadership\\nTeam.\\n\\nKey Responsibilities\\n• Product Owner - Manage & prioritize product backlog. Evangelize product feature with other\\nteams and enable more product adoption.\\n• Product Roadmap - Prepare roadmap for the product for the upcoming fiscal year.\\n• Sprint Planning & monitoring - Scoping, resource levelling / smoothing\\n• Stakeholder management - Manage key business stakeholders, get / set expectations and\\nmanage communication.\\n• Risk management & mitigation\\n• Co-ordinate cross functional teams for product releases\\n• Product Retirement - Plan and manage existing product retirement, interact, communicate with\\nall downstream systems to ensure product retirement and replacement is smooth.\\n• Product migration - Retire Informatica and migrate to Azure Data Factory for ETL process.\\n• Compliance Management\\n◦ Global Data Protection Regulation (GDPR) - Analyze, estimation and planning for the BI group.\\n\\nKey Skills - Microsoft Azure SQL DW, Azure Data Factory, SQL Server 2016, Power BI dashboard,\\nRest API\\n\\nhttps://www.indeed.com/r/Karthik-GV/1961c4eff806e6f4?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nMethodology - Agile model\\n\\nArchitect\\n\\nMicrosoft India -  Hyderabad, Telangana -\\n\\nSeptember 2013 to March 2016\\n\\nMcKesson, Singapore Provident Fund, SSE Home Services\\n\\nKey Responsibilities\\n• Delivery Management - Provide technical leadership and strategic direction to the testing\\norganization and project delivery team.\\n• Presales - Closely interact with customer & pre-sales team, response to RFP, Test estimates and\\nprepare Statement of Work. Won multiple test only engagements from CEE, LATAM, India region\\n• Test Strategy & Test Plan development & review for test only engagements.\\n• Test Consulting Services - Worked with the UK based customer \"SSE Home Services\" to provide\\ntest consultancy and technical guidance to the offshore TCS Kolkata team.\\n• Test Processes - Defined process steps and quality gates for test only engagements at\\norganization level.\\n• Quality Analysis - Analysis of trends in testing, identify best practices, improvement areas. I\\nhave prepared checklist for presales & delivery team that reduced the effort and cost of review\\nand lead to faster turnover to the customer.\\n• Project Recovery Team - I am one the key members in the project recovery team. I work closely\\nwith the project team and leadership to ensure that the project is recovered successfully. I have\\nsuccessfully recovered 3 critical project with high quality. In the current recovery project, I have\\nmanaged a team size of 103 team members.\\n• Project Delivery review- As a part of Technical Quality Assurance (TQA), I am the quality\\ngatekeeper for all dashboard projects (~30 projects) within Microsoft Global Delivery. All test\\nartifacts, test approach, test processes are reviewed and signed off during TQA review.\\n\\nKey Skills\\n\\nSr consultant\\n\\nMicrosoft India -  Hyderabad, Telangana -\\n\\nJune 2008 to March 2016\\n\\nSr Test Engineer\\n\\nMicrosoft India -  Hyderabad, Telangana -\\n\\nFebruary 2005 to June 2008\\n\\n2013, SQL Server 2014, Test automation using Coded UI, Selenium.\\n\\nEDUCATION\\n\\nPGDBM\\n\\nNarsee Monjee Institute of Management Studies\\n\\n\\n\\n2017 to 2018\\n\\nSKILLS\\n\\nProgram Management (2 years), Product Management (2 years), Quality Assurance (10+\\nyears), Business intelligence, Devops\\n\\nLINKS\\n\\nhttps://www.linkedin.com/in/karthik-g-v-7a25462\\n\\nAWARDS\\n\\nMicrosoft Technology Guru\\n\\nFebruary 2012\\n\\nMicrosoft Role Model\\n\\nJune 2007\\n\\nCERTIFICATIONS/LICENSES\\n\\nScrum Product Owner\\n\\nScrum Master\\n\\nCITA\\n\\nADDITIONAL INFORMATION\\n\\nMethodologies - Agile model, Iterative Model\\nTest Management - Resource forecasting, team sizing and budgeting, release planning, team\\nmanagement, technical\\nguidance to the team.\\n\\nRole: Sr. Consultant (June 2008 - Sep 2013)\\nExperience on managing test team for Data Warehouse / SQL Server BI, .Net App Development\\nProjects, API / Framework, Windows phone apps and Performance Testing engagements. Played\\nrole of Test Lead / Manager in all engagements.\\n\\nKey Projects - NHS UK, Baxter, ATI, Intel Corporation, Merck, EXL, Oman BI, PwC, ANZ Bank, SQL\\nServer PDW (Parallel Data-warehousing), Azure Cave tool\\n\\nKey Responsibilities\\n• Test Manager in all engagements.\\n• Test Planning & Execution - Define test strategy and test plan. Onboard resources allocate and\\ntrack tasks. Identify risks and mitigation plans.\\n• Define & implement Test Automation\\n• Performance test planning and execution\\n\\nhttps://www.linkedin.com/in/karthik-g-v-7a25462\\n\\n\\n• Define defect triage process with project & customer.\\n• Team Management - Managed maximum team size up to 8 resources.\\n\\nKey Skills\\nTechnologies - Visual Studio 2012, Microsoft Test Manager 2012, Azure, Test Automation using\\nCoded UI, Unit Test Framework, Performance testing using Visual Studio 2012, SQL Server 2012.\\nMethodologies - Iterative, Agile model, Test Driven Development (TDD)\\n\\nMicrosoft IT - India, BI CoE (Feb 2005 - June 2008)\\nThe Business Intelligence CoE in India manages multiple applications that require Data\\nWarehousing, Reporting, Analytical and other BI related Capabilities.\\n\\nRole: Test Lead\\nI was the test lead for multiple Data Warehousing / SQL Server BI projects. My primary role has\\nbeen the test lead for all these projects.\\n\\nKey Projects - MSSales, Rhythm of Business (RoB), Services Information Repository (SIR)\\n\\nKey Responsibilities\\n• Planning and Estimation of quarterly releases\\n• Define test strategy and Master Test Plan\\n• Review & Inspection of BRD, FSD, TSD, Test Cases & Test Plan\\n• Execution of Test Cases and defect logging.\\n• Conduct / participate in Defect Review meetings with the developers / client\\n• Analysis of Defects - Analysis of the root cause and the Injection phase of each defect.\\n• Test automation on MS BI, RoB, PTS Web, SIR & CFR.\\n• Team Management (includes FTEs) - managed team size of max 10 resources\\n\\nKey Skills\\nTechnologies -SQL Server 2000 / 2005 / 2008, SSRS, SSAS, SQL Server PI, SharePoint, Azure,\\nEnterprise Library\\nTools: Visual Studio 2012, QTP 8.2, TFS 2012.\\nSDLC & Test Methodologies - Agile methodology, Iterative model.\\n\\nRoyal Bank of Scotland, New Delhi Aug 2004 to Jan 2005 (6 months)\\nMy role as a Quality Engineer involved in\\n• Review of functional requirements\\n• Design test plan\\n• Design & review of test cases\\n• Test automation using Winrunner 7.6, QTP.\\n• Test case execution and defect reporting.\\n• Set up Performance testing environment-using Loadrunner. Completed a POC for performance\\ntesting of a D2K application.\\n\\nKey Skills Acquired\\nTechnologies: Oracle, D2K\\nTools: Winrunner 7.6, QTP 6.5, Test Director 7.6, Loadrunner 8.0, Clearcase, SQL Navigator\\n\\nSapient Corporation, New Delhi June 2003 to Aug 2004 (14 months)\\n\\n\\n\\nRole of Quality Engineer and primarily involved in\\n• Review of functional requirements.\\n• Create & execute system & Integration test cases in Test Director\\n• Test automation script development & execution using Winrunner 7.6.\\n• Maintenance of Test Automation environment.\\n• Production deployment support - Testing in Production.\\n\\nKey Skills Acquired\\nTechnologies: Java, JSP, Ariba 1.5\\nTools: Test Director 7.6, Toad, Winrunner 7.5, Trackgear 3.5, PVCS Tracker, WinCVS, Togetherj,\\nVisio, Winmerge', {'entities': [(4048, 4169, 'Skills'), (4034, 4038, 'Graduation Year'), (3977, 4022, 'College Name'), (3970, 3975, 'Degree'), (3841, 3850, 'Location'), (3822, 3837, 'Companies worked at'), (3804, 3820, 'Designation'), (3755, 3764, 'Location'), (3736, 3751, 'Companies worked at'), (3721, 3734, 'Designation'), (2053, 2062, 'Location'), (2034, 2049, 'Companies worked at'), (2023, 2032, 'Designation'), (493, 497, 'Graduation Year'), (452, 467, 'Companies worked at'), (217, 226, 'Location'), (198, 213, 'Companies worked at'), (187, 196, 'Designation'), (40, 49, 'Location'), (23, 38, 'Companies worked at'), (11, 20, 'Designation'), (0, 10, 'Name')]}), (\"Kartik Sharma\\nSystems Engineer - Infosys Ltd\\n\\nDelhi, Delhi - Email me on Indeed: indeed.com/r/Kartik-Sharma/cc7951fd7809f35e\\n\\n● Qualified B.Tech in Information Technology with 2.5 years overall and 2 years' experience in\\nSAP Security, Project Management and Software Support.\\n● Currently spearheading as Senior Systems Engineer with Infosys Ltd Pune, well versed in\\nAnalysis, Test and Support activities.\\n● Proficient in handling various projects and managing project risks. Possess up to date\\nknowledge of latest technological advancements, regulations and statutory compliances in the\\nindustry.\\n● Instrumental in building relations with upper level decision makers, seizing control of critical\\nproblem areas and delivering on client commitments.\\n\\nPROJECT ANNEXURE:\\n\\nProject Name: RB (Reckitt Benckiser)\\nDuration: Since April '16\\nRole: SAP Security Consultant\\nResponsibilities:\\n● Technical analyst for sap security in production and non-production environments.\\n● Worked with Security related tables such as AGR*, USR* etc.\\n● Performed User comparison using PFCG.\\n● Analysing user access issues using SU53 and system trace (ST01)\\n● Role changes done using PFCG as per the change request received.\\n● Mass user changes using SHDB, LSMW, SU10.\\n● Control Firefighter access in GRC10.1.\\n● Handling/Creating Solman CR as per Business requirement.\\n● Working on tool Service-Now for User/Business/Technical support.\\n\\nPROJECT KEY RESULT AREAS:\\n\\n● Extensive working knowledge in SAP ECC 6.0, SAP R/3 Enterprise GRC 10.1.\\n● Expertise in Role Administration, PFCG, User reports, Authorization objects.\\n● Expertise in Risk Analysis, Mitigation and Remediation.\\n● Utilize SU24 to enable/disable security checks\\n● Granting privileged and compensatory controls, providing access in controlled environment\\nusing Fire-fighter id.\\n● Troubleshoot security/authorization using SU53, ST01 and SUIM.\\n● Restrict table access through authorization groups.\\n● Ticket handling-related to various issues ranging from user expiration to missing\\nauthorizations.\\n● Addition, Removal of transaction codes, authorizations, authorization objects by modifying\\nexisting roles based upon change request.\\n● Supporting Site Go-Lives.\\n\\nWilling to relocate to: Delhi - Noida, Uttar Pradesh - Gurgaon, Haryana\\n\\nhttps://www.indeed.com/r/Kartik-Sharma/cc7951fd7809f35e?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nWORK EXPERIENCE\\n\\nSystems Engineer\\n\\nInfosys Ltd -  Delhi, Delhi -\\n\\nMarch 2016 to Present\\n\\nas a management trainee.\\n• Worked with 'AVS InfoTech' as a part-time employee.\\n• Guided students in Science, Math and C++ for 4 years.\\n\\nTECHNICAL SKILL SET\\n\\nSAP Systems: SAP ECC 6.0.\\nProduct Tools: GRC 10.1\\nDatabase: Oracle, SQL, RDBMS.\\n\\nSenior Systems engineer\\n\\nInfosys Limited -\\n\\nSeptember 2015 to Present\\n\\nWorking as SAP SECURITY consultant in a client project with Infosys\\n\\nEDUCATION\\n\\nB.Tech in Engineering\\n\\nNorthern India engineering college, IP UNIVERSITY DELHI\\n\\n2015\\n\\nCBSE\\n\\nLovely Public Sr. Sec. School\\n\\n2011\\n\\nCBSE\\n\\nLovely Public Sr. Sec. School\\n\\n2009\\n\\nUniversity / Board\\n\\nSKILLS\\n\\nSAP Security\\n\\n\\n\\nADDITIONAL INFORMATION\\n\\nOperating systems: Windows […] 8, 10.\\nLanguages: C, C++, C#\\n\\nPROFESSIONAL SKILL SET:\\n\\n• Good Communication Skills in English and Hindi.\\n• Ability to work under pressure.\", {'entities': [(3086, 3255, 'Skills'), (3046, 3058, 'Skills'), (2981, 3010, 'College Name'), (2975, 2979, 'Degree'), (2969, 2973, 'Graduation Year'), (2938, 2967, 'College Name'), (2932, 2936, 'Degree'), (2926, 2930, 'Graduation Year'), (2869, 2924, 'College Name'), (2846, 2868, 'Degree'), (2749, 2753, 'Graduation Year'), (2614, 2693, 'Skills'), (2425, 2430, 'Location'), (2418, 2423, 'Location'), (2385, 2401, 'Designation'), (2220, 2225, 'Location'), (837, 849, 'Skills'), (332, 344, 'Companies worked at'), (311, 327, 'Designation'), (221, 233, 'Skills'), (138, 170, 'Degree'), (81, 125, 'Email Address'), (53, 58, 'Location'), (46, 51, 'Location'), (32, 44, 'Companies worked at'), (14, 30, 'Designation'), (0, 13, 'Name')]}), (\"Kasturika Borah\\nTeam Member - Cisco\\n\\nBengaluru, Karnataka - Email me on Indeed: indeed.com/r/Kasturika-\\nBorah/9e71468914b38ee8\\n\\n• Software Engineer with overall 3+ years of experience in Network Monitoring system tool (EM7,\\nQuicksilver) Database tool (SQL, Maria DB) and reporting tool (Splunk) in all the releases.\\n• Relevant experience as a Test engineer for the releases includes Functional testing as well as\\nregression testing. Testing includes writing test cases, execute them and raise bugs.\\n• Relevant 1+ years of experience in handling releases for EM7 with proper documentation, Power\\npack creation and Tar creation for Sprint releases.\\n• Creating Splunk reports from last 6 months.\\n• Competent technical person involved in requirement gathering, analysis, design and coding.\\n• Experience in coding Python, SQL, and XML as per the requirement.\\n• Have knowledge in Event generating using traps and Syslog's generator.\\n• Exposure to Agile methodologies using Scrum Works framework, even handled scrum in the\\nteam\\n• Strong problem-solver who can design solutions and assist developers with issues.\\n• Excellent debugging and resolution skills.\\n• Good communication and interpersonal skills.\\n\\n• Working as Software Engineer for Cisco System India Private Ltd under Capgemini India Pvt.\\nLtd.. From May 25th 2017 till nowl\\n• Working as Software Engineer for Cisco System India Private Ltd under Randstad India Ltd.\\nFrom Dec 15 2014 till 30th April.\\n• Worked as Data Analyst for Fidelity India Financial Inc. from June 2013 till Oct 2014.\\n• Worked as Billing Analyst for IBM Daksh from March 2013 to June 2013.\\n\\nWilling to relocate to: Bengaluru, Karnataka\\n\\nWORK EXPERIENCE\\n\\nTeam Member\\n\\nCisco -\\n\\nOctober 2017 to Present\\n\\nEnvironment: Splunk\\nTechnologies: SPL command\\n\\nResponsibilities\\n• Involvement writing Splunk programming language and designing the report dashboard\\n• Following Agile methodology\\n• Develop the code on the design in splunk.\\n• Unit Testing and code review\\n\\nSenior developer and tester\\n\\nhttps://www.indeed.com/r/Kasturika-Borah/9e71468914b38ee8?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Kasturika-Borah/9e71468914b38ee8?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nCisco -\\n\\nDecember 2014 to Present\\n\\nEnvironment: EM7 platform, Quicksilver, SQL, oracle Toad\\nTechnologies: Python coding, xml coding, SQL query writing\\n\\nDescription\\nCisco Systems, Inc. (known as Cisco) is an American multinational technology conglomerate\\nheadquartered in San José, California, that develops, manufactures, and sells networking\\nhardware, telecommunications equipment, and other high-technology services and products\\n(www.cisco.com)\\n\\nResponsibilities\\n1. Developer of individual task on each release by weekly\\n• Need to do coding for new requirement.\\n• Also need to do end to end testing of all the events including Traps and Syslogs.\\n2. Database and Infrastructure Monitoring and Alerting related to device.\\n3. Involvement in documentation of release notes and preparation of a Regression testing at the\\nend of each release.\\n\\nTeam Member\\n\\nCisco -\\n\\nDecember 2014 to December 2017\\n\\nEnvironment: INFOVISTA (Vportal)\\nTechnologies: MS-Excel (sort, VLOOKUP), PPT\\n\\nResponsibilities\\n• Involvement in generating performance reports for certain customers at the starting of every\\nmonth\\n• Gathering the data from the INFOVISTA portal and sort it out as per month in the excel and\\ndesign the graphs for last consecutive\\n• Responsible for each data uploaded to the excel sheet and reviewing it before delivering\\n\\nFidelity national financial -\\n\\nJune 2013 to October 2014\\n\\nRole: QA and Report handling for the team\\nTechnologies: MS-Excel (sort, VLOOKUP), PPT, MS-Outlook\\n\\nResponsibilities\\n• Involvement in generating performance reports for the team at the end of each day and monthly\\nbased\\n• Responsible for each data uploaded to the excel sheet and sending it to the team manager\\n\\nEDUCATION\\n\\nCompucom Insitute of Information Technology\\n\\n\\n\\nrajasthan University\\n\\n2012\\n\\nSKILLS\\n\\nDatabase (3 years), Python (3 years), Splunk (Less than 1 year), SQL (3 years), xml (3 years)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS\\n\\n• Programming Languages: Python, XML\\n• Database: Maria-DB, sql\\n• Cisco Monitoring Tools: EM7\\n• Operating Systems: Windows/XP\\n• Reporting Tools: Vportal, Splunk\\n• Application & Web Servers: Sciencelogic (EM7), Syslog sender, Relay server.\\n• Data Structure Knowledge: Intermediate\", {'entities': [(4121, 4399, 'Skills'), (3984, 4078, 'Skills'), (3970, 3974, 'Graduation Year'), (3948, 3969, 'College Name'), (3901, 3945, 'College Name'), (3061, 3066, 'Companies worked at'), (3048, 3059, 'Designation'), (2402, 2407, 'Companies worked at'), (2372, 2377, 'Companies worked at'), (2208, 2213, 'Companies worked at'), (1690, 1695, 'Companies worked at'), (1677, 1688, 'Designation'), (1638, 1647, 'Location'), (1361, 1366, 'Companies worked at'), (1233, 1238, 'Companies worked at'), (72, 126, 'Email Address'), (37, 46, 'Location'), (30, 35, 'Companies worked at'), (16, 27, 'Designation'), (0, 15, 'Name')]})]\n",
            "Statring iteration 0\n",
            "{'ner': 6362.067694425583}\n",
            "Statring iteration 1\n",
            "{'ner': 718.6391411160467}\n",
            "Statring iteration 2\n",
            "{'ner': 526.3222110621282}\n",
            "Statring iteration 3\n",
            "{'ner': 642.9101031012142}\n",
            "Statring iteration 4\n",
            "{'ner': 423.05453826546625}\n",
            "Statring iteration 5\n",
            "{'ner': 449.64110325073483}\n",
            "Statring iteration 6\n",
            "{'ner': 488.32443949640856}\n",
            "Statring iteration 7\n",
            "{'ner': 566.613448461896}\n",
            "Statring iteration 8\n",
            "{'ner': 462.3250779715395}\n",
            "Statring iteration 9\n",
            "{'ner': 488.84388058157174}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-6ba846290b00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall : \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-score : \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mtrain_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-6ba846290b00>\u001b[0m in \u001b[0;36mtrain_spacy\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_to_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mdoc_gold_text\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_gold_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Not '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_type_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_type_\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Not '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_to_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mgold.pyx\u001b[0m in \u001b[0;36mspacy.gold.GoldParse.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mgold.pyx\u001b[0m in \u001b[0;36mspacy.gold.biluo_tags_from_offsets\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E103] Trying to set conflicting doc.ents: '(38, 58, 'Companies worked at')' and '(38, 44, 'Companies worked at')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap."
          ]
        }
      ],
      "source": [
        "############################################  NOTE  ########################################################\n",
        "#\n",
        "#           Creates NER training data in Spacy format from JSON downloaded from Dataturks.\n",
        "#\n",
        "#           Outputs the Spacy training data which can be used for Spacy training.\n",
        "#\n",
        "############################################################################################################\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from spacy.gold import GoldParse\n",
        "from spacy.scorer import Scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
        "    try:\n",
        "        training_data = []\n",
        "        lines=[]\n",
        "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            text = data['content']\n",
        "            entities = []\n",
        "            for annotation in data['annotation']:\n",
        "                #only a single point in text annotation.\n",
        "                point = annotation['points'][0]\n",
        "                labels = annotation['label']\n",
        "                # handle both list of labels or a single label.\n",
        "                if not isinstance(labels, list):\n",
        "                    labels = [labels]\n",
        "\n",
        "                for label in labels:\n",
        "                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
        "                    entities.append((point['start'], point['end'] + 1 ,label))\n",
        "\n",
        "\n",
        "            training_data.append((text, {\"entities\" : entities}))\n",
        "\n",
        "        return training_data\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
        "        return None\n",
        "\n",
        "import spacy\n",
        "################### Train Spacy NER.###########\n",
        "def train_spacy():\n",
        "\n",
        "    TRAIN_DATA = convert_dataturks_to_spacy(\"/content/traindatasmallset.json\")\n",
        "    print(TRAIN_DATA)\n",
        "    nlp = spacy.blank('en')  # create blank Language class\n",
        "    # create the built-in pipeline components and add them to the pipeline\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "       \n",
        "\n",
        "    # add labels\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(10):\n",
        "            print(\"Statring iteration \" + str(itn))\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            for text, annotations in TRAIN_DATA:\n",
        "                nlp.update(\n",
        "                    [text],  # batch of texts\n",
        "                    [annotations],  # batch of annotations\n",
        "                    drop=0.2,  # dropout - make it harder to memorise data\n",
        "                    sgd=optimizer,  # callable to update weights\n",
        "                    losses=losses)\n",
        "            print(losses)\n",
        "    #test the model and evaluate it\n",
        "    examples = convert_dataturks_to_spacy(\"/content/testdata.json\")\n",
        "    tp=0\n",
        "    tr=0\n",
        "    tf=0\n",
        "\n",
        "    ta=0\n",
        "    c=0        \n",
        "    for text,annot in examples:\n",
        "\n",
        "        f=open(\"resume\"+str(c)+\".txt\",\"w\")\n",
        "        doc_to_test=nlp(text)\n",
        "        d={}\n",
        "        for ent in doc_to_test.ents:\n",
        "            d[ent.label_]=[]\n",
        "        for ent in doc_to_test.ents:\n",
        "            d[ent.label_].append(ent.text)\n",
        "\n",
        "        for i in set(d.keys()):\n",
        "\n",
        "            f.write(\"\\n\\n\")\n",
        "            f.write(i +\":\"+\"\\n\")\n",
        "            for j in set(d[i]):\n",
        "                f.write(j.replace('\\n','')+\"\\n\")\n",
        "        d={}\n",
        "        for ent in doc_to_test.ents:\n",
        "            d[ent.label_]=[0,0,0,0,0,0]\n",
        "        for ent in doc_to_test.ents:\n",
        "            doc_gold_text= nlp.make_doc(text)\n",
        "            gold = GoldParse(doc_gold_text, entities=annot.get(\"entities\"))\n",
        "            y_true = [ent.label_ if ent.label_ in x else 'Not '+ent.label_ for x in gold.ner]\n",
        "            y_pred = [x.ent_type_ if x.ent_type_ ==ent.label_ else 'Not '+ent.label_ for x in doc_to_test]  \n",
        "            if(d[ent.label_][0]==0):\n",
        "                #f.write(\"For Entity \"+ent.label_+\"\\n\")   \n",
        "                #f.write(classification_report(y_true, y_pred)+\"\\n\")\n",
        "                (p,r,f,s)= precision_recall_fscore_support(y_true,y_pred,average='weighted')\n",
        "                a=accuracy_score(y_true,y_pred)\n",
        "                d[ent.label_][0]=1\n",
        "                d[ent.label_][1]+=p\n",
        "                d[ent.label_][2]+=r\n",
        "                d[ent.label_][3]+=f\n",
        "                d[ent.label_][4]+=a\n",
        "                d[ent.label_][5]+=1\n",
        "        c+=1\n",
        "    for i in d:\n",
        "        print(\"\\n For Entity \"+i+\"\\n\")\n",
        "        print(\"Accuracy : \"+str((d[i][4]/d[i][5])*100)+\"%\")\n",
        "        print(\"Precision : \"+str(d[i][1]/d[i][5]))\n",
        "        print(\"Recall : \"+str(d[i][2]/d[i][5]))\n",
        "        print(\"F-score : \"+str(d[i][3]/d[i][5]))\n",
        "train_spacy()"
      ]
    }
  ]
}